{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to read data from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch.utils import normalizeString\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "csv_sep = \"\\t\"\n",
    "\n",
    "def prepare_data_from_file(dataset_path):\n",
    "    with open(dataset_path, \"r\", encoding=\"utf8\") as ds_fio:\n",
    "        df_list = ds_fio.readlines()\n",
    "        for i in range(len(df_list)):\n",
    "            tmp_split_row = df_list[i].split(csv_sep)\n",
    "            df_list[i] = tmp_split_row[:3]\n",
    "    dataset_pd = pd.DataFrame(df_list, columns=[\"s1\", \"s2\", \"label\"])\n",
    "    dataset_pd[\"s1\"] = dataset_pd[\"s1\"].str.strip()\n",
    "    dataset_pd[\"s2\"] = dataset_pd[\"s2\"].str.strip()\n",
    "    dataset_pd[\"label\"] = dataset_pd[\"label\"].str.strip()\n",
    "\n",
    "    dataset_pd[\"combine\"] = dataset_pd[\"s1\"] + \" + \" + dataset_pd[\"s2\"]\n",
    "    dataset_pd[\"combine\"] = dataset_pd[\"combine\"].apply(normalizeString)\n",
    "\n",
    "    X_train, y_train = np.asarray(dataset_pd[\"combine\"]), np.asarray(dataset_pd[\"label\"])\n",
    "    for i in range(len(y_train)):\n",
    "        y_train[i] = 1 if y_train[i] == \"TRUE\" else 0\n",
    "    return X_train, y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"./dataset/dataset-unfiltered.txt\"\n",
    "X_train, y_train = prepare_data_from_file(dataset_path)\n",
    "\n",
    "X_tokenized = [[w.strip() for w in combine.split(\" \")] for combine in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.Word2Vec(sentences = X_tokenized, vector_size=120, min_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for machine learning methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_vector(combine):\n",
    "    tokens = combine.split(\" \")\n",
    "    vector = [model.wv[tok.strip()] for tok in tokens]\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_path = \"./dataset/finetuned-train.txt\"\n",
    "dataset_test_path = \"./dataset/finetuned-test.txt\"\n",
    "\n",
    "X_train, y_train = prepare_data_from_file(dataset_train_path)\n",
    "X_test, y_test = prepare_data_from_file(dataset_test_path)\n",
    "\n",
    "# Convert y from 1D to 2D\n",
    "y_train = [[x] for x in y_train]\n",
    "y_test = [[x] for x in y_test]\n",
    "\n",
    "# Convert word to vector by using pretrained Word2Vec model\n",
    "X_train_vec = [generate_vector(x) for x in X_train]\n",
    "X_test_vec = [generate_vector(x) for x in X_test]\n",
    "\n",
    "# Convert word vector from 2D to 1D\n",
    "X_train_vec_1d = [np.mean(x, axis=0) for x in X_train_vec]\n",
    "X_test_vec_1d = [np.mean(x, axis=0) for x in X_test_vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385023 385023\n",
      "82504 82504\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_vec_1d), len(y_train))\n",
    "print(len(X_test_vec_1d), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "import timeit\n",
    "\n",
    "def calculate_metrics(label, predict):\n",
    "    print('Accuracy score: ', accuracy_score(label, predict))\n",
    "    print('Precision: ', precision_score(label, predict))\n",
    "    print('Recall score: ', recall_score(label, predict))\n",
    "    print('F1 score: ', f1_score(label, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS TK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  13954.243618999999\n",
      "Inference time:  2614.9085180999973\n",
      "Accuracy score:  0.8495466886453991\n",
      "Precision:  0.8474996987588866\n",
      "Recall score:  0.85249200038786\n",
      "F1 score:  0.8499885192212407\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "# Train SVM model\n",
    "start_train = timeit.default_timer()\n",
    "ml_svm = svm.SVC()\n",
    "ml_svm.fit(X_train_vec_1d, y_train)\n",
    "stop_train = timeit.default_timer()\n",
    "print(\"Training time: \", stop_train - start_train)\n",
    "\n",
    "# SVM predict\n",
    "start_inference = timeit.default_timer()\n",
    "pred_svm = ml_svm.predict(X_test_vec_1d)\n",
    "stop_inference = timeit.default_timer()\n",
    "print(\"Inference time: \", stop_inference - start_inference)\n",
    "\n",
    "# Print metric\n",
    "calculate_metrics(y_test, pred_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUSTK~1\\AppData\\Local\\Temp/ipykernel_24076/3893218134.py:6: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  model_random_forest.fit(X_train_vec_1d, y_train)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  866.4750711000015\n",
      "Inference time:  3.0066845000001194\n",
      "Accuracy score:  0.8640187142441579\n",
      "Precision:  0.8880533374680207\n",
      "Recall score:  0.8330505187627266\n",
      "F1 score:  0.8596730415639969\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train Random forest model\n",
    "start_train = timeit.default_timer()\n",
    "model_random_forest = RandomForestClassifier()\n",
    "model_random_forest.fit(X_train_vec_1d, y_train)\n",
    "stop_train = timeit.default_timer()\n",
    "print(\"Training time: \", stop_train - start_train)\n",
    "\n",
    "# SVM predict\n",
    "start_inference = timeit.default_timer()\n",
    "pred_randomforest = model_random_forest.predict(X_test_vec_1d)\n",
    "stop_inference = timeit.default_timer()\n",
    "print(\"Inference time: \", stop_inference - start_inference)\n",
    "\n",
    "# Print metric\n",
    "calculate_metrics(y_test, pred_randomforest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS TK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  1978.349807999999\n",
      "Inference time:  0.3221551000024192\n",
      "Accuracy score:  0.7665688936293998\n",
      "Precision:  0.8057045953684913\n",
      "Recall score:  0.7025598758848056\n",
      "F1 score:  0.7506053895860042\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Train Gradient boosted trees model\n",
    "start_train = timeit.default_timer()\n",
    "model_gradient_boost = GradientBoostingClassifier()\n",
    "model_gradient_boost.fit(X_train_vec_1d, y_train)\n",
    "stop_train = timeit.default_timer()\n",
    "print(\"Training time: \", stop_train - start_train)\n",
    "\n",
    "# Gradient boosted trees predict\n",
    "start_inference = timeit.default_timer()\n",
    "pred_gradientboostedtrees = model_gradient_boost.predict(X_test_vec_1d)\n",
    "stop_inference = timeit.default_timer()\n",
    "print(\"Inference time: \", stop_inference - start_inference)\n",
    "\n",
    "# Print metric\n",
    "calculate_metrics(y_test, pred_gradientboostedtrees)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS TK\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time:  1.1154857000001357\n",
      "Inference time:  0.40788859999884153\n",
      "Accuracy score:  0.5854382817802773\n",
      "Precision:  0.6142056317034444\n",
      "Recall score:  0.4594928730728207\n",
      "F1 score:  0.5257027165698279\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Train Naive Bayes model\n",
    "start_train = timeit.default_timer()\n",
    "model_naive_bayes = GaussianNB()\n",
    "model_naive_bayes.fit(X_train_vec_1d, y_train)\n",
    "stop_train = timeit.default_timer()\n",
    "print(\"Training time: \", stop_train - start_train)\n",
    "\n",
    "# Naive Bayes predict\n",
    "start_inference = timeit.default_timer()\n",
    "pred_naive_bayes = model_naive_bayes.predict(X_test_vec_1d)\n",
    "stop_inference = timeit.default_timer()\n",
    "print(\"Inference time: \", stop_inference - start_inference)\n",
    "\n",
    "# Print metric\n",
    "calculate_metrics(y_test, pred_naive_bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e32c473f9ae643a177d9aed137210c843a2749e204593912b966393b5abcabe7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
