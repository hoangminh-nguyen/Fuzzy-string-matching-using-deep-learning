{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate & Combine vectors Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatch import inference as trans_inference\n",
    "from DeezyMatch import combine_vecs_trans\n",
    "\n",
    "def generate_vectors_trans(model_name, query_path, candidates_path, scenario=\"trans\", inference=trans_inference):\n",
    "  input_file_path = \"./models/\" + model_name + \"/input_dfm_rnn.yaml\"\n",
    "  pretrained_model_path = \"./models/\" + model_name + \"/\" + model_name + \".model\"\n",
    "  pretrained_vocab_path = \"./models/\" + model_name + \"/\" + model_name + \".vocab\"\n",
    "\n",
    "  # generate query vector\n",
    "  inference(input_file_path=input_file_path,\n",
    "              dataset_path= query_path, \n",
    "              pretrained_model_path=pretrained_model_path, \n",
    "              pretrained_vocab_path=pretrained_vocab_path,\n",
    "              inference_mode=\"vect\",\n",
    "              scenario=\"./queries/\"+scenario)\n",
    "  \n",
    "  # generate candidates vector\n",
    "  inference(input_file_path=input_file_path,\n",
    "              dataset_path=candidates_path, \n",
    "              pretrained_model_path=pretrained_model_path, \n",
    "              pretrained_vocab_path=pretrained_vocab_path,\n",
    "              inference_mode=\"vect\",\n",
    "              scenario=\"./candidates/\"+scenario)\n",
    "\n",
    "def combine_vector_trans(scenario, model_name):\n",
    "    # combine query\n",
    "    combine_vecs_trans(model_name=model_name,\n",
    "                input_scenario=\"./queries/\"+scenario, \n",
    "                output_scenario=\"./combined/queries_\"+scenario, \n",
    "                print_every=10)\n",
    "    \n",
    "    # combine candidates\n",
    "    combine_vecs_trans(model_name=model_name,\n",
    "                input_scenario=\"./candidates/\"+scenario, \n",
    "                output_scenario=\"./combined/candidates_\"+scenario, \n",
    "                print_every=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate & Combine vectors GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeezyMatchBase.DeezyMatch import inference as gru_inference\n",
    "from DeezyMatchBase.DeezyMatch import combine_vecs\n",
    "\n",
    "def generate_vectors_gru(model_name, query_path, candidates_path, scenario=\"gru\", inference=gru_inference):\n",
    "    input_file_path = \"./models/\" + model_name + \"/input_dfm_rnn.yaml\"\n",
    "    pretrained_model_path = \"./models/\" + model_name + \"/\" + model_name + \".model\"\n",
    "    pretrained_vocab_path = \"./models/\" + model_name + \"/\" + model_name + \".vocab\"\n",
    "\n",
    "    # generate query vector\n",
    "    inference(input_file_path=input_file_path,\n",
    "                dataset_path= query_path, \n",
    "                pretrained_model_path=pretrained_model_path, \n",
    "                pretrained_vocab_path=pretrained_vocab_path,\n",
    "                inference_mode=\"vect\",\n",
    "                scenario=\"./queries/\"+scenario)\n",
    "  \n",
    "    # generate candidates vector\n",
    "    inference(input_file_path=input_file_path,\n",
    "                dataset_path=candidates_path, \n",
    "                pretrained_model_path=pretrained_model_path, \n",
    "                pretrained_vocab_path=pretrained_vocab_path,\n",
    "                inference_mode=\"vect\",\n",
    "                scenario=\"./candidates/\"+scenario)\n",
    "\n",
    "def combine_vector_gru(scenario):\n",
    "    # combine query\n",
    "    combine_vecs(input_scenario=\"./queries/\"+scenario, \n",
    "                output_scenario=\"./combined/queries_\"+scenario, \n",
    "                print_every=10)\n",
    "    \n",
    "    # combine candidates\n",
    "    combine_vecs(input_scenario=\"./candidates/\"+scenario, \n",
    "                output_scenario=\"./combined/candidates_\"+scenario, \n",
    "                print_every=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "queries = \"Michael Jackson\"\n",
    "candidates = [\"Michael Jackson\", \"Micheal Jackson\", \"MichaelJackson\", \"Michael-Jackson\", \n",
    "              \"Michael Joseph Jackson\", \"Michael Joe Jackson\", \"Jackson, Michael\", \n",
    "              \"Jackson, Michael Joseph\", \"Майкл Джексон\", \"Μάϊκλ Τζάκσον\", \"マイケルジャクソン\", \n",
    "              \"M. J.\", \"M. Jackson\", \"Michael J. Jackson\", \"M. J. Jackson\", \"Mr. Jackson\", 'MJ', \n",
    "              \"King of Pop\"]\n",
    "              \n",
    "queries_path= \"./dataset/queries.txt\"\n",
    "candidates_path= \"./dataset/candidates.txt\"\n",
    "more_candidates_path= \"./dataset/more-candidates.txt\"\n",
    "\n",
    "# Parameters\n",
    "threshold = 0.8\n",
    "num_candidates = 20\n",
    "search_size = 10\n",
    "number_test_rows = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monge-Elkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monge-Elkan: 7 results\n",
      "1.0 Michael Jackson\n",
      "0.98 Micheal Jackson\n",
      "0.98 Jackson, Michael\n",
      "0.92 Michael Joseph Jackson\n",
      "0.92 Michael J. Jackson\n",
      "0.91 Michael Joe Jackson\n",
      "0.91 Jackson, Michael Joseph\n"
     ]
    }
   ],
   "source": [
    "import DeezyMatch.traditional_string_matching as traditional_method\n",
    "\n",
    "result = {}\n",
    "for cand in candidates:\n",
    "    score = traditional_method.monge_elkan(queries, cand)\n",
    "    if (score >= threshold):\n",
    "        result[cand] = str(score)[:4]\n",
    "\n",
    "re = dict(sorted(result.items(), key=lambda item: item[1], reverse=True))\n",
    "print(\"Monge-Elkan:\", len(re), \"results\")\n",
    "for x in re:\n",
    "    print(re[x], x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2022-08-29 14:09:49\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread input file: ./models/finetuned_gru_wikidata_23072022/input_dfm_rnn.yaml\u001b[0m\n",
      "\u001b[92m2022-08-29 14:09:50\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mpytorch will use: cpu\u001b[0m\n",
      "\u001b[92m2022-08-29 14:09:54\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread CSV file: ./dataset/queries.txt\u001b[0m\n",
      "\u001b[92m2022-08-29 14:09:54\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mnumber of labels, True: 1 and False: 0\u001b[0m\n",
      "\u001b[92m2022-08-29 14:09:54\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mskipping 0 lines\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2022-08-29 14:09:54\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32msave test-data-class: d:\\KLTN\\DeezyMatch-master\\queries\\gru\\dataframe.df\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2022-08-29 14:09:54\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mh1_shape[0,1] torch.Size([1, 64])\u001b[0m\n",
      "--- 4.0658605098724365 seconds ---\n",
      "\u001b[92m2022-08-29 14:09:54\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread input file: ./models/finetuned_gru_wikidata_23072022/input_dfm_rnn.yaml\u001b[0m\n",
      "\u001b[92m2022-08-29 14:09:54\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mpytorch will use: cpu\u001b[0m\n",
      "\u001b[92m2022-08-29 14:09:56\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread CSV file: ./dataset/candidates.txt\u001b[0m\n",
      "\u001b[92m2022-08-29 14:09:56\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mnumber of labels, True: 23 and False: 0\u001b[0m\n",
      "\u001b[92m2022-08-29 14:09:56\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mskipping 0 lines\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2022-08-29 14:09:56\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32msave test-data-class: d:\\KLTN\\DeezyMatch-master\\candidates\\gru\\dataframe.df\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2022-08-29 14:09:56\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mh1_shape[0,1] torch.Size([23, 64])\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.657121181488037 seconds ---\n",
      "\u001b[92m2022-08-29 14:09:56\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread input file: ./queries/gru\\input_dfm_rnn.yaml\u001b[0m\n",
      "\u001b[92m2022-08-29 14:09:56\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mpytorch will use: cpu\u001b[0m\n",
      "\n",
      "\n",
      "-- Combine vectors\n",
      "Reading vectors from ./queries/gru\\embeddings\\rnn_fwd*\n",
      "0000000 ./queries/gru\\embeddings\\rnn_fwd_0\n",
      "\n",
      "\n",
      "-- Combine IDs\n",
      "\n",
      "0000000 ./queries/gru\\embeddings\\rnn_indxs_0\n",
      "\n",
      "\n",
      "-- Combine vectors\n",
      "Reading vectors from ./queries/gru\\embeddings\\rnn_bwd*\n",
      "0000000 ./queries/gru\\embeddings\\rnn_bwd_0\n",
      "\n",
      "\n",
      "-- Combine IDs\n",
      "\n",
      "0000000 ./queries/gru\\embeddings\\rnn_indxs_0\n",
      "--- 15.810302495956421 seconds ---\n",
      "\u001b[92m2022-08-29 14:09:56\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread input file: ./candidates/gru\\input_dfm_rnn.yaml\u001b[0m\n",
      "\u001b[92m2022-08-29 14:09:56\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mpytorch will use: cpu\u001b[0m\n",
      "\n",
      "\n",
      "-- Combine vectors\n",
      "Reading vectors from ./candidates/gru\\embeddings\\rnn_fwd*\n",
      "0000000 ./candidates/gru\\embeddings\\rnn_fwd_0\n",
      "\n",
      "\n",
      "-- Combine IDs\n",
      "\n",
      "0000000 ./candidates/gru\\embeddings\\rnn_indxs_0\n",
      "\n",
      "\n",
      "-- Combine vectors\n",
      "Reading vectors from ./candidates/gru\\embeddings\\rnn_bwd*\n",
      "0000000 ./candidates/gru\\embeddings\\rnn_bwd_0\n",
      "\n",
      "\n",
      "-- Combine IDs\n",
      "\n",
      "0000000 ./candidates/gru\\embeddings\\rnn_indxs_0\n",
      "--- 15.90627670288086 seconds ---\n",
      "\u001b[92m2022-08-29 14:09:56\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread input file: ./combined/candidates_gru\\input_dfm_rnn.yaml\u001b[0m\n",
      "\u001b[92m2022-08-29 14:09:56\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mpytorch will use: cpu\u001b[0m\n",
      "Is faiss_id_candis already trained? True\n",
      "=========== Start the search for 0 Michael Jackson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1/1 -- Number of found candidates so far: 9, searched: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1/1 -- Number of found candidates so far: 14, searched: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1/1 -- Number of found candidates so far: 15, searched: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME: 2.4386560916900635\n"
     ]
    }
   ],
   "source": [
    "from DeezyMatch import candidate_ranker\n",
    "\n",
    "model_name=\"finetuned_gru_wikidata_23072022\"\n",
    "scenario=\"gru\"\n",
    "\n",
    "generate_vectors_gru(model_name, queries_path, candidates_path, scenario=scenario)\n",
    "combine_vector_gru(scenario)\n",
    "\n",
    "candidates_pd = \\\n",
    "    candidate_ranker(query_scenario=\"./combined/queries_\"+scenario,\n",
    "                    candidate_scenario=\"./combined/candidates_\"+scenario, \n",
    "                    ranking_metric=\"conf\", \n",
    "                    selection_threshold=threshold, \n",
    "                    num_candidates=num_candidates, \n",
    "                    search_size=search_size, \n",
    "                    output_path=\"./ranker_results/\"+scenario, \n",
    "                    pretrained_model_path=\"./models/\"+model_name+\"/\"+model_name+\".model\", \n",
    "                    pretrained_vocab_path=\"./models/\"+model_name+\"/\"+model_name+\".vocab\", \n",
    "                    number_test_rows=number_test_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael Jackson\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Michael Jackson', 0.9972),\n",
       "             ('Michael-Jackson', 0.9961),\n",
       "             ('Michael Joe Jackson', 0.9951),\n",
       "             ('Micheal Jackson', 0.9947),\n",
       "             ('Michael J. Jackson', 0.9935),\n",
       "             ('MichaelJackson', 0.9935),\n",
       "             ('Майкл Джексон', 0.9891),\n",
       "             ('M. J. Jackson', 0.9762),\n",
       "             ('M. Jackson', 0.9723),\n",
       "             ('Μάϊκλ Τζάκσον', 0.9631),\n",
       "             ('Mr. Jackson', 0.9477),\n",
       "             ('マイケルジャクソン', 0.9059),\n",
       "             ('mary jackson', 0.9046),\n",
       "             ('Michael Joseph Jackson', 0.8855),\n",
       "             ('Jackson, Michael', 0.8672)])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos=0\n",
    "print(candidates_pd.iloc[pos][\"query\"])\n",
    "candidates_pd.iloc[pos][\"pred_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2022-08-29 14:10:03\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread input file: ./models/finetuned_transformer_wikidata_28072022/input_dfm_rnn.yaml\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:03\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mpytorch will use: cpu\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:07\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread CSV file: ./dataset/queries.txt\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:07\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mnumber of labels, True: 1 and False: 0\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:07\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mskipping 0 lines\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2022-08-29 14:10:07\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32msave test-data-class: d:\\KLTN\\DeezyMatch-master\\queries\\trans\\dataframe.df\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3.4216957092285156 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2022-08-29 14:10:07\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread input file: ./models/finetuned_transformer_wikidata_28072022/input_dfm_rnn.yaml\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:07\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mpytorch will use: cpu\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:08\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread CSV file: ./dataset/candidates.txt\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:08\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mnumber of labels, True: 23 and False: 0\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:08\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mskipping 0 lines\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2022-08-29 14:10:09\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32msave test-data-class: d:\\KLTN\\DeezyMatch-master\\candidates\\trans\\dataframe.df\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.664137363433838 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2022-08-29 14:10:09\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread input file: ./queries/trans\\input_dfm_rnn.yaml\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:09\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mpytorch will use: cpu\u001b[0m\n",
      "\n",
      "\n",
      "-- Combine vectors\n",
      "Reading vectors from ./queries/trans\\embeddings\\finetuned_transformer_wikidata_28072022_vecs_*\n",
      "list_files:  ['./queries/trans\\\\embeddings\\\\finetuned_transformer_wikidata_28072022_vecs_0']\n",
      "0000000 ./queries/trans\\embeddings\\finetuned_transformer_wikidata_28072022_vecs_0\n",
      "0\n",
      "\n",
      "\n",
      "-- Combine IDs\n",
      "0000000 ./queries/trans\\embeddings\\finetuned_transformer_wikidata_28072022_indxs_0\n",
      "\n",
      "--- 31.385404586791992 seconds ---\n",
      "\u001b[92m2022-08-29 14:10:09\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread input file: ./candidates/trans\\input_dfm_rnn.yaml\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:09\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mpytorch will use: cpu\u001b[0m\n",
      "\n",
      "\n",
      "-- Combine vectors\n",
      "Reading vectors from ./candidates/trans\\embeddings\\finetuned_transformer_wikidata_28072022_vecs_*\n",
      "list_files:  ['./candidates/trans\\\\embeddings\\\\finetuned_transformer_wikidata_28072022_vecs_0']\n",
      "0000000 ./candidates/trans\\embeddings\\finetuned_transformer_wikidata_28072022_vecs_0\n",
      "0\n",
      "\n",
      "\n",
      "-- Combine IDs\n",
      "0000000 ./candidates/trans\\embeddings\\finetuned_transformer_wikidata_28072022_indxs_0\n",
      "\n",
      "--- 31.492273092269897 seconds ---\n",
      "\u001b[92m2022-08-29 14:10:09\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread input file: ./combined/candidates_trans\\input_dfm_rnn.yaml\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:09\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mpytorch will use: cpu\u001b[0m\n",
      "Is faiss_id_candis already trained? True\n",
      "=========== Start the search for 0 Michael Jackson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1/1 -- Number of found candidates so far: 10, searched: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1/1 -- Number of found candidates so far: 16, searched: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1/1 -- Number of found candidates so far: 18, searched: 23\n",
      "TOTAL TIME: 1.9621846675872803\n"
     ]
    }
   ],
   "source": [
    "from DeezyMatch import candidate_ranker_trans\n",
    "\n",
    "model_name=\"finetuned_transformer_wikidata_28072022\"\n",
    "scenario=\"trans\"\n",
    "#scenario=\"morecand\"\n",
    "\n",
    "generate_vectors_trans(model_name, queries_path, candidates_path, scenario=scenario)\n",
    "combine_vector_trans(scenario, model_name)\n",
    "\n",
    "candidates_pd = \\\n",
    "    candidate_ranker_trans(model_name=model_name,\n",
    "                    query_scenario=\"./combined/queries_\"+scenario,\n",
    "                    candidate_scenario=\"./combined/candidates_\"+scenario, \n",
    "                    ranking_metric=\"conf\", \n",
    "                    selection_threshold=threshold,\n",
    "                    num_candidates=num_candidates, \n",
    "                    search_size=search_size, \n",
    "                    output_path=\"./ranker_results/\"+scenario, \n",
    "                    pretrained_model_path=\"./models/\"+model_name+\"/\"+model_name+\".model\", \n",
    "                    pretrained_vocab_path=\"./models/\"+model_name+\"/\"+model_name+\".vocab\", \n",
    "                    number_test_rows=number_test_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael Jackson\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('Майкл Джексон', 0.9973),\n",
       "             ('Michael J. Jackson', 0.9972),\n",
       "             ('Michael Jackson', 0.9957),\n",
       "             ('Micheal Jackson', 0.9954),\n",
       "             ('Michael Joe Jackson', 0.9947),\n",
       "             ('MichaelJackson', 0.9893),\n",
       "             ('Jackson, Michael', 0.9882),\n",
       "             ('Michael-Jackson', 0.9871),\n",
       "             ('Michael Joseph Jackson', 0.9775),\n",
       "             ('M. Jackson', 0.9774),\n",
       "             ('M. J. Jackson', 0.9747),\n",
       "             ('Μάϊκλ Τζάκσον', 0.946),\n",
       "             ('Jackson, Michael Joseph', 0.9397),\n",
       "             ('マイケルジャクソン', 0.9297),\n",
       "             ('mary jackson', 0.8918),\n",
       "             ('Mr. Jackson', 0.8912),\n",
       "             ('M. J.', 0.8871),\n",
       "             ('MJ', 0.8149)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos=0\n",
    "print(candidates_pd.iloc[pos][\"query\"])\n",
    "candidates_pd.iloc[pos][\"pred_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2022-08-29 14:10:17\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread input file: ./models/finetuned_transformer_wikidata_28072022/input_dfm_rnn.yaml\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:17\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mpytorch will use: cpu\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:19\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread CSV file: ./dataset/database-a.txt\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:19\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mnumber of labels, True: 15 and False: 0\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:19\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mskipping 0 lines\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2022-08-29 14:10:19\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32msave test-data-class: d:\\KLTN\\DeezyMatch-master\\queries\\matching\\dataframe.df\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.80362868309021 seconds ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2022-08-29 14:10:19\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread input file: ./models/finetuned_transformer_wikidata_28072022/input_dfm_rnn.yaml\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:19\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mpytorch will use: cpu\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:21\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread CSV file: ./dataset/database-b.txt\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:21\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mnumber of labels, True: 41 and False: 0\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:21\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mskipping 0 lines\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m2022-08-29 14:10:21\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32msave test-data-class: d:\\KLTN\\DeezyMatch-master\\candidates\\matching\\dataframe.df\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1.99454927444458 seconds ---\n",
      "\u001b[92m2022-08-29 14:10:21\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread input file: ./queries/matching\\input_dfm_rnn.yaml\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:21\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mpytorch will use: cpu\u001b[0m\n",
      "\n",
      "\n",
      "-- Combine vectors\n",
      "Reading vectors from ./queries/matching\\embeddings\\finetuned_transformer_wikidata_28072022_vecs_*\n",
      "list_files:  ['./queries/matching\\\\embeddings\\\\finetuned_transformer_wikidata_28072022_vecs_0']\n",
      "0000000 ./queries/matching\\embeddings\\finetuned_transformer_wikidata_28072022_vecs_0\n",
      "0\n",
      "\n",
      "\n",
      "-- Combine IDs\n",
      "0000000 ./queries/matching\\embeddings\\finetuned_transformer_wikidata_28072022_indxs_0\n",
      "\n",
      "--- 43.69518852233887 seconds ---\n",
      "\u001b[92m2022-08-29 14:10:21\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread input file: ./candidates/matching\\input_dfm_rnn.yaml\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:21\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mpytorch will use: cpu\u001b[0m\n",
      "\n",
      "\n",
      "-- Combine vectors\n",
      "Reading vectors from ./candidates/matching\\embeddings\\finetuned_transformer_wikidata_28072022_vecs_*\n",
      "list_files:  ['./candidates/matching\\\\embeddings\\\\finetuned_transformer_wikidata_28072022_vecs_0']\n",
      "0000000 ./candidates/matching\\embeddings\\finetuned_transformer_wikidata_28072022_vecs_0\n",
      "0\n",
      "\n",
      "\n",
      "-- Combine IDs\n",
      "0000000 ./candidates/matching\\embeddings\\finetuned_transformer_wikidata_28072022_indxs_0\n",
      "\n",
      "--- 43.78310489654541 seconds ---\n",
      "\u001b[92m2022-08-29 14:10:21\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[2;32mread input file: ./combined/candidates_matching\\input_dfm_rnn.yaml\u001b[0m\n",
      "\u001b[92m2022-08-29 14:10:21\u001b[0m \u001b[95mHOANG-MINH-LAPTOP\u001b[0m \u001b[1m\u001b[90m[INFO]\u001b[0m \u001b[1;32mpytorch will use: cpu\u001b[0m\n",
      "Is faiss_id_candis already trained? True\n",
      "=========== Start the search for 0 Michael Jackson\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1/15 -- Number of found candidates so far: 2, searched: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1/15 -- Number of found candidates so far: 2, searched: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1/15 -- Number of found candidates so far: 2, searched: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1/15 -- Number of found candidates so far: 2, searched: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1/15 -- Number of found candidates so far: 2, searched: 41\n",
      "=========== Start the search for 1 Jo Young-jin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 2/15 -- Number of found candidates so far: 2, searched: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 2/15 -- Number of found candidates so far: 2, searched: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 2/15 -- Number of found candidates so far: 2, searched: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 2/15 -- Number of found candidates so far: 2, searched: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 2/15 -- Number of found candidates so far: 2, searched: 41\n",
      "=========== Start the search for 2 P. H. Polk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 3/15 -- Number of found candidates so far: 1, searched: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 3/15 -- Number of found candidates so far: 1, searched: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 3/15 -- Number of found candidates so far: 1, searched: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 3/15 -- Number of found candidates so far: 1, searched: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 3/15 -- Number of found candidates so far: 1, searched: 41\n",
      "=========== Start the search for 3 W. Aveman\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 4/15 -- Number of found candidates so far: 1, searched: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 4/15 -- Number of found candidates so far: 1, searched: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 4/15 -- Number of found candidates so far: 1, searched: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 4/15 -- Number of found candidates so far: 1, searched: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 4/15 -- Number of found candidates so far: 1, searched: 41\n",
      "=========== Start the search for 4 G. F. Watts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 5/15 -- Number of found candidates so far: 1, searched: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 5/15 -- Number of found candidates so far: 1, searched: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 5/15 -- Number of found candidates so far: 1, searched: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 5/15 -- Number of found candidates so far: 1, searched: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 5/15 -- Number of found candidates so far: 1, searched: 41\n",
      "=========== Start the search for 5 Deming W. M.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 6/15 -- Number of found candidates so far: 1, searched: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 6/15 -- Number of found candidates so far: 1, searched: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 6/15 -- Number of found candidates so far: 1, searched: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 6/15 -- Number of found candidates so far: 1, searched: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 6/15 -- Number of found candidates so far: 1, searched: 41\n",
      "=========== Start the search for 6 Charlotte Höglund\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 7/15 -- Number of found candidates so far: 2, searched: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 7/15 -- Number of found candidates so far: 2, searched: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 7/15 -- Number of found candidates so far: 2, searched: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 7/15 -- Number of found candidates so far: 2, searched: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 7/15 -- Number of found candidates so far: 2, searched: 41\n",
      "=========== Start the search for 7 Александър Николов\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 8/15 -- Number of found candidates so far: 3, searched: 10\n",
      "=========== Start the search for 8 Alfred Apaka\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 9/15 -- Number of found candidates so far: 1, searched: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 9/15 -- Number of found candidates so far: 1, searched: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 9/15 -- Number of found candidates so far: 1, searched: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 9/15 -- Number of found candidates so far: 1, searched: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 9/15 -- Number of found candidates so far: 1, searched: 41\n",
      "=========== Start the search for 9 Carol Celeste Carmichael Parks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 10/15 -- Number of found candidates so far: 1, searched: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 10/15 -- Number of found candidates so far: 1, searched: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 10/15 -- Number of found candidates so far: 1, searched: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 10/15 -- Number of found candidates so far: 1, searched: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 10/15 -- Number of found candidates so far: 1, searched: 41\n",
      "=========== Start the search for 10 卡羅爾·布魯斯\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 11/15 -- Number of found candidates so far: 2, searched: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 11/15 -- Number of found candidates so far: 2, searched: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 11/15 -- Number of found candidates so far: 2, searched: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 11/15 -- Number of found candidates so far: 2, searched: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 11/15 -- Number of found candidates so far: 2, searched: 41\n",
      "=========== Start the search for 11 Robert Phillips\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 12/15 -- Number of found candidates so far: 1, searched: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 12/15 -- Number of found candidates so far: 1, searched: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 12/15 -- Number of found candidates so far: 1, searched: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 12/15 -- Number of found candidates so far: 1, searched: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 12/15 -- Number of found candidates so far: 1, searched: 41\n",
      "=========== Start the search for 12 Adrian Targon\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 13/15 -- Number of found candidates so far: 2, searched: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 13/15 -- Number of found candidates so far: 2, searched: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 13/15 -- Number of found candidates so far: 2, searched: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 13/15 -- Number of found candidates so far: 2, searched: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 13/15 -- Number of found candidates so far: 2, searched: 41\n",
      "=========== Start the search for 13 Hoang Minh\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 14/15 -- Number of found candidates so far: 2, searched: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 14/15 -- Number of found candidates so far: 2, searched: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 14/15 -- Number of found candidates so far: 2, searched: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 14/15 -- Number of found candidates so far: 2, searched: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 14/15 -- Number of found candidates so far: 2, searched: 41\n",
      "=========== Start the search for 14 Do Thi Thanh Ha\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 15/15 -- Number of found candidates so far: 1, searched: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 15/15 -- Number of found candidates so far: 1, searched: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 15/15 -- Number of found candidates so far: 1, searched: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 15/15 -- Number of found candidates so far: 1, searched: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 15/15 -- Number of found candidates so far: 1, searched: 41\n",
      "TOTAL TIME: 12.561673402786255\n"
     ]
    }
   ],
   "source": [
    "from DeezyMatch import candidate_ranker_trans\n",
    "\n",
    "databaseA =\"./dataset/database-a.txt\"\n",
    "databaseB =\"./dataset/database-b.txt\"\n",
    "\n",
    "model_name=\"finetuned_transformer_wikidata_28072022\"\n",
    "scenario=\"matching\"\n",
    "\n",
    "generate_vectors_trans(model_name, databaseA, databaseB, scenario=scenario)\n",
    "combine_vector_trans(scenario, model_name)\n",
    "\n",
    "candidates_pd = \\\n",
    "    candidate_ranker_trans(model_name=model_name,\n",
    "                    query_scenario=\"./combined/queries_\"+scenario,\n",
    "                    candidate_scenario=\"./combined/candidates_\"+scenario, \n",
    "                    ranking_metric=\"conf\", \n",
    "                    selection_threshold=0.85, \n",
    "                    num_candidates=3, \n",
    "                    search_size=10, \n",
    "                    output_path=\"./ranker_results/\"+scenario, \n",
    "                    pretrained_model_path=\"./models/\"+model_name+\"/\"+model_name+\".model\", \n",
    "                    pretrained_vocab_path=\"./models/\"+model_name+\"/\"+model_name+\".vocab\", \n",
    "                    number_test_rows=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michael Jackson   --->   M. J. Jackson\n",
      "Jo Young-jin   --->   Youngjin Cho\n",
      "P. H. Polk   --->   Polk Prentice H.\n",
      "W. Aveman   --->   Avemann Wolfgang\n",
      "G. F. Watts   --->   George Fred Watts\n",
      "Deming W. M.   --->   Deming Wilber Merton\n",
      "Charlotte Höglund   --->   Eva Charlotte Höglund\n",
      "Александър Николов   --->   Aleksandar Nikolov\n",
      "Alfred Apaka   --->   Alfred Aholo Afat Jr.\n",
      "Carol Celeste Carmichael Parks   --->   Carol Parks\n",
      "卡羅爾·布魯斯   --->   Carol Bruce\n",
      "Robert Phillips   --->   Bob Phillips\n",
      "Adrian Targon   --->   Aart Targon\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(candidates_pd)):\n",
    "    query = candidates_pd.iloc[i][\"query\"]\n",
    "    cand = list(candidates_pd.iloc[i][\"pred_score\"])[0]\n",
    "    score = list(candidates_pd.iloc[i][\"pred_score\"].values())[0]\n",
    "    #print(\". Score: \", score, \"\\t\", query, \"  --->  \", cand)\n",
    "    print(query, \"  --->  \", cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___ Michael Jackson\n",
      "0.9747   M. J. Jackson\n",
      "0.8918   mary jackson\n",
      "\n",
      "___ Jo Young-jin\n",
      "0.971   Youngjin Cho\n",
      "0.9174   Johan Young\n",
      "\n",
      "___ P. H. Polk\n",
      "0.8502   Polk Prentice H.\n",
      "\n",
      "___ W. Aveman\n",
      "0.8639   Avemann Wolfgang\n",
      "\n",
      "___ G. F. Watts\n",
      "0.9703   George Fred Watts\n",
      "\n",
      "___ Deming W. M.\n",
      "0.9683   Deming Wilber Merton\n",
      "\n",
      "___ Charlotte Höglund\n",
      "0.9537   Eva Charlotte Höglund\n",
      "0.9146   Aart Targon\n",
      "\n",
      "___ Александър Николов\n",
      "0.9994   Aleksandar Nikolov\n",
      "0.9112   Bill Jackson\n",
      "0.8598   Stevland Judkins\n",
      "\n",
      "___ Alfred Apaka\n",
      "0.8839   Alfred Aholo Afat Jr.\n",
      "\n",
      "___ Carol Celeste Carmichael Parks\n",
      "0.9712   Carol Parks\n",
      "\n",
      "___ 卡羅爾·布魯斯\n",
      "0.9743   Carol Bruce\n",
      "0.9151   Carol Parks\n",
      "\n",
      "___ Robert Phillips\n",
      "0.962   Bob Phillips\n",
      "\n",
      "___ Adrian Targon\n",
      "0.9761   Aart Targon\n",
      "0.9251   Adriana\n",
      "\n",
      "___ Hoang Minh\n",
      "0.9311   H. Minh\n",
      "0.8587   Avemann Wolfgang\n",
      "\n",
      "___ Do Thi Thanh Ha\n",
      "0.9479   Ha Do\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(candidates_pd)):\n",
    "    query = candidates_pd.iloc[i][\"query\"]\n",
    "    cand = list(candidates_pd.iloc[i][\"pred_score\"])\n",
    "    score = list(candidates_pd.iloc[i][\"pred_score\"].values())\n",
    "    #print(\". Score: \", score, \"\\t\", query, \"  --->  \", cand)\n",
    "    print(\"___\", query)\n",
    "    for i in range(0,len(cand)):\n",
    "        print(score[i], \" \", cand[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e32c473f9ae643a177d9aed137210c843a2749e204593912b966393b5abcabe7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
